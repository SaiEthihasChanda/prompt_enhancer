{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31391057-82a3-4569-b64e-05ccefc93ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6854a63-9dfc-4401-8b89-9a54d4685298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b83043-66b2-4474-ba85-b456a6230010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compose', 'drop a line', 'indite', 'pen', 'publish', 'save', 'spell', 'write']\n"
     ]
    }
   ],
   "source": [
    "import synonyms as syn\n",
    "print(syn.get_all_synonyms(\"write\", pos=syn.wordnet.VERB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d8fde7-7b3b-41d3-b16c-a719538f1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_verbs_from_dataset(data):\n",
    "    verbs = set()\n",
    "    for original, enhanced in data:\n",
    "        for text in [original, enhanced]:\n",
    "            tokens = word_tokenize(text.lower())\n",
    "            for token in tokens:\n",
    "                if is_verb(token):\n",
    "                    verbs.add(token)\n",
    "    return sorted(list(verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a16a767-fda1-4c44-b683-6210469d7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_verb(word):\n",
    "    synsets = wordnet.synsets(word, pos=wordnet.VERB)\n",
    "    return len(synsets) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e3cc9d-c64c-4971-b62f-b2096c7ed2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(data, augment_factor=10):\n",
    "    augmented_data = data.copy()\n",
    "    \n",
    "    # Expanded synonym dictionary\n",
    "    verbs = extract_verbs_from_dataset(augmented_data)\n",
    "    \n",
    "    synonyms = {}\n",
    "    for verb in verbs:\n",
    "        print(verb)\n",
    "        synonyms[verb] = syn.get_all_synonyms(verb, pos=syn.wordnet.VERB)\n",
    "    print(synonyms)\n",
    "    \n",
    "    for _ in range(augment_factor):\n",
    "        for original, enhanced in data:\n",
    "            new_original, new_enhanced = original, enhanced\n",
    "            \n",
    "            # Synonym Replacement\n",
    "            for word, syn_list in synonyms.items():\n",
    "                if random.random() < 0.4:  # 40% chance to replace\n",
    "                    new_original = new_original.replace(word, random.choice(syn_list))\n",
    "                    new_enhanced = new_enhanced.replace(word, random.choice(syn_list))\n",
    "            \n",
    "            # Paraphrasing\n",
    "            if random.random() < 0.5:\n",
    "                if new_original.startswith('Can you'):\n",
    "                    new_original = new_original.replace('Can you', random.choice(['How do I', 'Show me how to', 'What is the way to']), 1)\n",
    "                elif new_original.startswith('I need'):\n",
    "                    new_original = new_original.replace('I need', random.choice(['Show me how to', 'I want to know how to']), 1)\n",
    "            \n",
    "            # Filler Word Addition/Removal\n",
    "            fillers = ['please', 'kindly', 'in detail', 'comprehensive', 'step-by-step']\n",
    "            if random.random() < 0.5:\n",
    "                words = new_original.split()\n",
    "                insert_pos = random.randint(1, len(words))\n",
    "                filler = random.choice(fillers)\n",
    "                new_original = ' '.join(words[:insert_pos] + [filler] + words[insert_pos:])\n",
    "            else:\n",
    "                for filler in fillers:\n",
    "                    new_original = new_original.replace(filler, '').strip()\n",
    "            \n",
    "            # Verb Variation (for enhanced)\n",
    "            verbs = ['Explain', 'Write', 'Debug', 'Create', 'Implement', 'Describe', 'Develop']\n",
    "            if random.random() < 0.4:\n",
    "                for verb in verbs:\n",
    "                    if new_enhanced.startswith(verb):\n",
    "                        new_enhanced = new_enhanced.replace(verb, random.choice(verbs), 1)\n",
    "                        break\n",
    "            \n",
    "            # Random Cropping\n",
    "            if random.random() < 0.3 and len(new_original.split()) > 5:\n",
    "                words = new_original.split()\n",
    "                start = random.randint(0, 2)\n",
    "                end = len(words) - random.randint(0, 2)\n",
    "                new_original = ' '.join(words[start:end])\n",
    "            \n",
    "            # Random Word Shuffling (add noise)\n",
    "            if random.random() < 0.2:\n",
    "                words = new_original.split()\n",
    "                if len(words) > 3:\n",
    "                    i, j = random.sample(range(len(words)), 2)\n",
    "                    words[i], words[j] = words[j], words[i]\n",
    "                    new_original = ' '.join(words)\n",
    "            \n",
    "            # Add augmented pair if different\n",
    "            if (new_original, new_enhanced) != (original, enhanced):\n",
    "                augmented_data.append((new_original, new_enhanced))\n",
    "    \n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4585dafa-a675-4f16-bfe2-3ce2ef1ce9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return [(item['original'], item['enhanced']) for item in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0786f8-9bac-49b8-b303-92f37fcfdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    vocab = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
    "    word_count = {}\n",
    "    for text in texts:\n",
    "        for word in word_tokenize(text.lower()):\n",
    "            word_count[word] = word_count.get(word, 0) + 1\n",
    "    for word, count in word_count.items():\n",
    "        if count >= 1:  # Include all words (small dataset)\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab, {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10987c12-5d87-4823-a826-7cb54a40aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_augmented_dataset(data, file_path='augmented_programming_prompts.json'):\n",
    "    json_data = [{'original': orig, 'enhanced': enh} for orig, enh in data]\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f30efc2-e473-4321-911c-d36bc8ee8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_convert(text, vocab, max_len):\n",
    "    tokens = word_tokenize(text.lower())[:max_len-1]\n",
    "    token_ids = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "    token_ids = [vocab['<SOS>']] + token_ids + [vocab['<EOS>']]\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids += [vocab['<PAD>']] * (max_len - len(token_ids))\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f851b5d-c57f-4423-9ae1-1af3fccfcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_len=50):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.data[idx]\n",
    "        src_ids = tokenize_and_convert(src, self.vocab, self.max_len)\n",
    "        tgt_ids = tokenize_and_convert(tgt, self.vocab, self.max_len)\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468cc5f3-d1ea-4a14-8ffa-7d464c66a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=128, hidden_size=256):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.encoder = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        vocab_size = self.fc.out_features\n",
    "        \n",
    "        # Encoder\n",
    "        embedded = self.embedding(src)\n",
    "        enc_output, (hidden, cell) = self.encoder(embedded)\n",
    "        \n",
    "        # Decoder\n",
    "        outputs = torch.zeros(batch_size, tgt_len-1, vocab_size).to(src.device)\n",
    "        dec_input = tgt[:, 0].unsqueeze(1)  # Start with <SOS>\n",
    "        dec_hidden = (hidden, cell)\n",
    "        \n",
    "        for t in range(tgt_len-1):\n",
    "            dec_embed = self.embedding(dec_input)\n",
    "            dec_output, dec_hidden = self.decoder(dec_embed, dec_hidden)\n",
    "            output = self.fc(dec_output.squeeze(1))\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            # Teacher forcing\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                dec_input = tgt[:, t+1].unsqueeze(1)\n",
    "            else:\n",
    "                dec_input = output.argmax(1).unsqueeze(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d84e14d-e660-49c7-b73e-1498fbf632cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=30, lr=0.001, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore <PAD>\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Anneal teacher forcing ratio\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        tf_ratio = max(0.1, 0.5 - (0.4 * epoch / epochs))\n",
    "        \n",
    "        for src, tgt in train_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt, teacher_forcing_ratio=tf_ratio)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), tgt[:, 1:].contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in val_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "                loss = criterion(output.view(-1, output.size(-1)), tgt[:, 1:].contiguous().view(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Log sample output\n",
    "        if epoch % 5 == 0:\n",
    "            sample_src, _ = val_loader.dataset[0]\n",
    "            sample_prompt = ' '.join([inv_vocab.get(t.item(), '<UNK>') for t in sample_src if t.item() not in [0, 1, 2]])\n",
    "            enhanced = enhance_prompt(model, sample_prompt, vocab, inv_vocab, device=device)\n",
    "            print(f'Epoch {epoch+1}, Sample Input: {sample_prompt}')\n",
    "            print(f'Epoch {epoch+1}, Sample Output: {enhanced}')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, TF Ratio: {tf_ratio:.2f}')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'prompt_enhancer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f287f494-0e9f-4859-bd11-4a9b6de38e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_prompt(model, prompt, vocab, inv_vocab, max_len=50, device='cpu'):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    token_ids = tokenize_and_convert(prompt, vocab, max_len)\n",
    "    src = torch.tensor([token_ids]).to(device)\n",
    "    \n",
    "    # Encoder\n",
    "    embedded = model.embedding(src)\n",
    "    _, (hidden, cell) = model.encoder(embedded)\n",
    "    \n",
    "    # Decoder\n",
    "    dec_input = torch.tensor([[vocab['<SOS>']]]).to(device)\n",
    "    output_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        dec_embed = model.embedding(dec_input)\n",
    "        dec_output, (hidden, cell) = model.decoder(dec_embed, (hidden, cell))\n",
    "        output = model.fc(dec_output.squeeze(1))\n",
    "        pred_token = output.argmax(1).item()\n",
    "        if pred_token == vocab['<EOS>']:\n",
    "            break\n",
    "        output_tokens.append(pred_token)\n",
    "        dec_input = torch.tensor([[pred_token]]).to(device)\n",
    "    \n",
    "    return ' '.join(inv_vocab.get(t, '<UNK>') for t in output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5f9999-1382-4254-be07-ef1d4fc25748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions\n",
      "approach\n",
      "array\n",
      "arrays\n",
      "automate\n",
      "bash\n",
      "best\n",
      "build\n",
      "builded\n",
      "calculate\n",
      "can\n",
      "check\n",
      "clarify\n",
      "closures\n",
      "code\n",
      "codeed\n",
      "compare\n",
      "connect\n",
      "connecting\n",
      "construct\n",
      "constructed\n",
      "containerize\n",
      "control\n",
      "create\n",
      "debug\n",
      "deliver\n",
      "describe\n",
      "detail\n",
      "detailed\n",
      "develop\n",
      "developed\n",
      "do\n",
      "elucidate\n",
      "email\n",
      "execute\n",
      "executeed\n",
      "explain\n",
      "fault\n",
      "fetch\n",
      "figure\n",
      "file\n",
      "files\n",
      "find\n",
      "fix\n",
      "function\n",
      "functions\n",
      "game\n",
      "give\n",
      "go\n",
      "guide\n",
      "handle\n",
      "hash\n",
      "help\n",
      "illustrate\n",
      "implement\n",
      "implemented\n",
      "is\n",
      "join\n",
      "know\n",
      "learn\n",
      "linked\n",
      "list\n",
      "looking\n",
      "merge\n",
      "need\n",
      "number\n",
      "offer\n",
      "optimize\n",
      "out\n",
      "parse\n",
      "perform\n",
      "phone\n",
      "please\n",
      "present\n",
      "process\n",
      "processing\n",
      "program\n",
      "programming\n",
      "project\n",
      "promises\n",
      "provide\n",
      "query\n",
      "queue\n",
      "repair\n",
      "resolve\n",
      "rest\n",
      "reverse\n",
      "scrape\n",
      "scraping\n",
      "script\n",
      "search\n",
      "sequence\n",
      "set\n",
      "setting\n",
      "show\n",
      "solve\n",
      "sort\n",
      "sorted\n",
      "sorting\n",
      "stack\n",
      "steps\n",
      "string\n",
      "structure\n",
      "structures\n",
      "struggling\n",
      "supply\n",
      "supposed\n",
      "sways\n",
      "table\n",
      "tables\n",
      "tell\n",
      "tests\n",
      "troubleshoot\n",
      "trying\n",
      "understand\n",
      "understanding\n",
      "up\n",
      "uploads\n",
      "use\n",
      "using\n",
      "validate\n",
      "want\n",
      "web\n",
      "write\n",
      "writing\n",
      "wrong\n",
      "{'actions': ['accomplish', 'action', 'carry out', 'carry through', 'execute', 'fulfil', 'fulfill', 'litigate', 'process', 'sue'], 'approach': ['approach', 'border on', 'come near', 'come on', 'draw close', 'draw near', 'go about', 'go up', 'near', 'set about'], 'array': ['align', 'array', 'lay out', 'range', 'set out'], 'arrays': ['align', 'array', 'lay out', 'range', 'set out'], 'automate': ['automate', 'automatise', 'automatize'], 'bash': ['bash', 'bonk', 'bop', 'sock', 'whap', 'whop'], 'best': ['best', 'outdo', 'outflank', 'scoop', 'trump'], 'build': ['build', 'build up', 'construct', 'establish', 'make', 'progress', 'ramp up', 'work up'], 'builded': ['build', 'build up', 'construct', 'establish', 'make', 'progress', 'ramp up', 'work up'], 'calculate': ['account', 'aim', 'bet', 'calculate', 'cipher', 'compute', 'count', 'count on', 'cypher', 'depend', 'direct', 'estimate', 'figure', 'forecast', 'look', 'reckon', 'work out'], 'can': ['can', 'dismiss', 'displace', 'fire', 'force out', 'give notice', 'give the axe', 'give the sack', 'put up', 'sack', 'send away', 'terminate', 'tin'], 'check': ['agree', 'arrest', 'ascertain', 'assure', 'break', 'check', 'check into', 'check off', 'check out', 'check over', 'check up on', 'checker', 'chequer', 'chink', 'condition', 'contain', 'control', 'correspond', 'crack', 'curb', 'delay', 'determine', 'discipline', 'ensure', 'find out', 'fit', 'gibe', 'go over', 'hold', 'hold back', 'hold in', 'insure', 'jibe', 'learn', 'look into', 'mark', 'mark off', 'match', 'moderate', 'retard', 'see', 'see to it', 'stop', 'suss out', 'tally', 'tick', 'tick off', 'train', 'turn back', 'watch'], 'clarify': ['clarify', 'clear up', 'elucidate'], 'closures': ['closure', 'cloture'], 'code': ['cipher', 'code', 'cypher', 'encipher', 'encrypt', 'inscribe', 'write in code'], 'codeed': ['cipher', 'code', 'cypher', 'encipher', 'encrypt', 'inscribe', 'write in code'], 'compare': ['compare', 'equate', 'liken'], 'connect': ['associate', 'colligate', 'connect', 'get in touch', 'join', 'link', 'link up', 'plug in', 'plug into', 'relate', 'tie', 'tie in', 'touch base', 'unite'], 'connecting': ['associate', 'colligate', 'connect', 'get in touch', 'join', 'link', 'link up', 'plug in', 'plug into', 'relate', 'tie', 'tie in', 'touch base', 'unite'], 'construct': ['build', 'construct', 'fabricate', 'make', 'manufacture', 'reconstruct', 'retrace'], 'constructed': ['build', 'construct', 'fabricate', 'make', 'manufacture', 'reconstruct', 'retrace'], 'containerize': ['containerise', 'containerize'], 'control': ['ascertain', 'assure', 'check', 'command', 'contain', 'control', 'curb', 'ensure', 'hold', 'hold in', 'insure', 'keep in line', 'manipulate', 'master', 'moderate', 'operate', 'see', 'see to it', 'verify'], 'create': ['create', 'make', 'produce'], 'debug': ['debug'], 'deliver': ['bear', 'birth', 'cede', 'deliver', 'deport', 'drive home', 'extradite', 'fork out', 'fork over', 'fork up', 'give birth', 'give up', 'hand over', 'have', 'pitch', 'present', 'redeem', 'render', 'rescue', 'return', 'save', 'surrender', 'turn in'], 'describe': ['account', 'delineate', 'depict', 'describe', 'discover', 'distinguish', 'draw', 'identify', 'key', 'key out', 'line', 'name', 'report', 'trace'], 'detail': ['detail'], 'detailed': ['detail'], 'develop': ['acquire', 'arise', 'break', 'build up', 'develop', 'educate', 'evolve', 'explicate', 'formulate', 'germinate', 'get', 'grow', 'make grow', 'modernise', 'modernize', 'originate', 'prepare', 'produce', 'recrudesce', 'rise', 'spring up', 'train', 'uprise'], 'developed': ['acquire', 'arise', 'break', 'build up', 'develop', 'educate', 'evolve', 'explicate', 'formulate', 'germinate', 'get', 'grow', 'make grow', 'modernise', 'modernize', 'originate', 'prepare', 'produce', 'recrudesce', 'rise', 'spring up', 'train', 'uprise'], 'do': ['act', 'answer', 'arrange', 'behave', 'cause', 'coif', 'coiffe', 'coiffure', 'come', 'do', 'dress', 'execute', 'exercise', 'fare', 'get along', 'make', 'make out', 'manage', 'perform', 'practice', 'practise', 'serve', 'set', 'suffice'], 'elucidate': ['clarify', 'clear', 'clear up', 'crystalise', 'crystalize', 'crystallise', 'crystallize', 'elucidate', 'enlighten', 'illuminate', 'shed light on', 'sort out', 'straighten out'], 'email': ['e-mail', 'email', 'netmail'], 'execute': ['accomplish', 'action', 'carry out', 'carry through', 'do', 'execute', 'fulfil', 'fulfill', 'perform', 'put to death', 'run'], 'executeed': ['accomplish', 'action', 'carry out', 'carry through', 'do', 'execute', 'fulfil', 'fulfill', 'perform', 'put to death', 'run'], 'explain': ['excuse', 'explain', 'explicate'], 'fault': ['blame', 'fault'], 'fetch': ['bring', 'bring in', 'convey', 'fetch', 'get'], 'figure': ['calculate', 'cipher', 'compute', 'count on', 'cypher', 'enter', 'envision', 'estimate', 'fancy', 'figure', 'forecast', 'image', 'picture', 'project', 'reckon', 'see', 'visualise', 'visualize', 'work out'], 'file': ['charge', 'file', 'file away', 'lodge', 'register'], 'files': ['charge', 'file', 'file away', 'lodge', 'register'], 'find': ['ascertain', 'bump', 'chance', 'come up', 'detect', 'determine', 'discover', 'encounter', 'feel', 'find', 'find oneself', 'find out', 'get', 'get hold', 'happen', 'incur', 'line up', 'notice', 'observe', 'obtain', 'receive', 'recover', 'regain', 'retrieve', 'rule', 'see', 'witness'], 'fix': ['bushel', 'cook', 'define', 'deposit', 'desex', 'desexualise', 'desexualize', 'determine', 'doctor', 'fasten', 'fix', 'fixate', 'furbish up', 'gear up', 'get', 'limit', 'make', 'mend', 'pay back', 'pay off', 'posit', 'prepare', 'ready', 'repair', 'restore', 'secure', 'set', 'set up', 'situate', 'specify', 'sterilise', 'sterilize', 'touch on', 'unsex'], 'function': ['function', 'go', 'officiate', 'operate', 'run', 'serve', 'work'], 'functions': ['function', 'go', 'officiate', 'operate', 'run', 'serve', 'work'], 'game': ['back', 'bet on', 'gage', 'game', 'punt', 'stake'], 'give': ['afford', 'apply', 'break', 'cave in', 'chip in', 'collapse', 'commit', 'consecrate', 'contribute', 'dedicate', 'devote', 'ease up', 'establish', 'fall in', 'feed', 'founder', 'generate', 'gift', 'give', 'give way', 'grant', 'hand', 'have', 'hold', 'impart', 'kick in', 'leave', 'make', 'move over', 'open', 'pass', 'pass on', 'pay', 'present', 'reach', 'render', 'return', 'sacrifice', 'throw', 'turn over', 'yield'], 'go': ['become', 'belong', 'blend', 'blend in', 'break', 'break down', 'buy the farm', \"cash in one's chips\", 'choke', 'conk', 'conk out', 'croak', 'decease', 'depart', 'die', 'drop dead', 'endure', 'exit', 'expire', 'extend', 'fail', 'fit', 'function', 'get', 'get going', 'give out', 'give way', 'give-up the ghost', 'go', 'go away', 'go bad', 'hold out', 'hold up', 'kick the bucket', 'last', 'lead', 'live', 'live on', 'locomote', 'move', 'operate', 'pass', 'pass away', 'perish', 'plump', 'pop off', 'proceed', 'rifle', 'run', 'run low', 'run short', 'snuff it', 'sound', 'start', 'survive', 'travel', 'work'], 'guide': ['channelise', 'channelize', 'conduct', 'direct', 'draw', 'guide', 'guide on', 'head', 'lead', 'maneuver', 'manoeuver', 'manoeuvre', 'pass', 'point', 'run', 'steer', 'take'], 'handle': ['address', 'care', 'cover', 'deal', 'do by', 'handle', 'manage', 'palm', 'plow', 'treat', 'wield'], 'hash': ['hash'], 'help': ['aid', 'assist', 'avail', 'facilitate', 'help', 'help oneself', 'serve'], 'illustrate': ['exemplify', 'illustrate', 'instance'], 'implement': ['apply', 'carry out', 'enforce', 'follow out', 'follow through', 'follow up', 'go through', 'implement', 'put through'], 'implemented': ['apply', 'carry out', 'enforce', 'follow out', 'follow through', 'follow up', 'go through', 'implement', 'put through'], 'is': ['be', 'comprise', 'constitute', 'cost', 'embody', 'equal', 'exist', 'follow', 'live', 'make up', 'personify', 'represent'], 'join': ['bring together', 'conjoin', 'connect', 'fall in', 'get together', 'join', 'link', 'link up', 'unite'], 'know': ['acknowledge', 'bang', 'be intimate', 'bed', 'bonk', 'cognise', 'cognize', 'do it', 'eff', 'experience', 'fuck', 'get it on', 'get laid', 'have a go at it', 'have intercourse', 'have it away', 'have it off', 'have sex', 'hump', 'jazz', 'know', 'lie with', 'live', 'love', 'make love', 'make out', 'recognise', 'recognize', 'roll in the hay', 'screw', 'sleep together', 'sleep with'], 'learn': ['acquire', 'ascertain', 'check', 'con', 'determine', 'discover', 'find out', 'get a line', 'get wind', 'get word', 'hear', 'instruct', 'larn', 'learn', 'memorise', 'memorize', 'pick up', 'read', 'see', 'study', 'take', 'teach', 'watch'], 'linked': ['associate', 'colligate', 'connect', 'join', 'link', 'link up', 'relate', 'tie', 'tie in', 'unite', 'yoke'], 'list': ['heel', 'lean', 'list', 'name', 'number'], 'looking': ['appear', 'attend', 'await', 'bet', 'calculate', 'count', 'depend', 'expect', 'face', 'front', 'look', 'reckon', 'search', 'see', 'seem', 'take care', 'wait'], 'merge': ['blend', 'coalesce', 'combine', 'commingle', 'conflate', 'flux', 'fuse', 'immix', 'meld', 'merge', 'mix', 'unify', 'unite'], 'need': ['ask', 'call for', 'demand', 'involve', 'necessitate', 'need', 'postulate', 'require', 'take', 'want'], 'number': ['add up', 'amount', 'come', 'count', 'enumerate', 'keep down', 'list', 'number', 'numerate', 'total'], 'offer': ['bid', 'declare oneself', 'extend', 'offer', 'offer up', 'pop the question', 'proffer', 'propose', 'provide', 'put up', 'tender', 'volunteer'], 'optimize': ['optimise', 'optimize'], 'out': ['come out', 'come out of the closet', 'out'], 'parse': ['parse'], 'perform': ['do', 'execute', 'perform'], 'phone': ['call', 'call up', 'phone', 'ring', 'telephone'], 'please': ['delight', 'please'], 'present': ['acquaint', 'award', 'confront', 'deliver', 'demo', 'demonstrate', 'exhibit', 'face', 'gift', 'give', 'introduce', 'lay out', 'portray', 'pose', 'present', 'represent', 'salute', 'show', 'stage', 'submit'], 'process': ['action', 'litigate', 'march', 'process', 'serve', 'sue', 'swear out', 'treat', 'work', 'work on'], 'processing': ['action', 'litigate', 'march', 'process', 'serve', 'sue', 'swear out', 'treat', 'work', 'work on'], 'program': ['program', 'programme'], 'programming': ['program', 'programme'], 'project': ['cast', 'contrive', 'design', 'envision', 'externalise', 'externalize', 'fancy', 'figure', 'image', 'jut', 'jut out', 'picture', 'plan', 'project', 'propose', 'protrude', 'see', 'send off', 'stick out', 'throw', 'visualise', 'visualize'], 'promises': ['anticipate', 'assure', 'call', 'forebode', 'foretell', 'predict', 'prognosticate', 'promise'], 'provide': ['allow', 'allow for', 'bring home the bacon', 'cater', 'furnish', 'leave', 'offer', 'ply', 'provide', 'put up', 'render', 'supply'], 'query': ['query', 'question'], 'queue': ['line up', 'queue', 'queue up'], 'repair': ['amend', 'animate', 'bushel', 'compensate', 'doctor', 'fix', 'furbish up', 'indemnify', 'mend', 'quicken', 'reanimate', 'recompense', 'recreate', 'rectify', 'remediate', 'remedy', 'renovate', 'repair', 'resort', 'restore', 'revive', 'revivify', 'touch on', 'vivify'], 'resolve': ['adjudicate', 'answer', 'break up', 'conclude', 'decide', 'dissolve', 'purpose', 'resolve', 'settle', 'solve'], 'rest': ['breathe', \"catch one's breath\", 'lie', 'perch', 'pillow', 'remain', 'repose', 'reside', 'rest', 'roost', 'stay', 'take a breather'], 'reverse': ['annul', 'change by reversal', 'countermand', 'invert', 'lift', 'override', 'overrule', 'overthrow', 'overturn', 'repeal', 'rescind', 'reverse', 'revoke', 'turn', 'turn back', 'vacate'], 'scrape': ['come up', 'genuflect', 'grate', 'kowtow', 'scrape', 'scrape up', 'scratch', 'scratch up', 'skin'], 'scraping': ['altercate', 'argufy', 'come up', 'dispute', 'genuflect', 'grate', 'junk', 'kowtow', 'quarrel', 'scrap', 'scrape', 'scrape up', 'scratch', 'scratch up', 'skin', 'trash'], 'script': ['script'], 'search': ['explore', 'look', 'look for', 'research', 'search', 'seek'], 'sequence': ['sequence'], 'set': ['adjust', 'arrange', 'coif', 'coiffe', 'coiffure', 'congeal', 'correct', 'countersink', 'define', 'determine', 'do', 'dress', 'fix', 'fructify', 'gear up', 'go down', 'go under', 'jell', 'lay', 'lay out', 'limit', 'localise', 'localize', 'mark', 'place', 'plant', 'pose', 'position', 'prepare', 'put', 'ready', 'rig', 'set', 'set up', 'sic', 'specify', 'typeset'], 'setting': ['adjust', 'arrange', 'coif', 'coiffe', 'coiffure', 'congeal', 'correct', 'countersink', 'define', 'determine', 'do', 'dress', 'fix', 'fructify', 'gear up', 'go down', 'go under', 'jell', 'lay', 'lay out', 'limit', 'localise', 'localize', 'mark', 'place', 'plant', 'pose', 'position', 'prepare', 'put', 'ready', 'rig', 'set', 'set up', 'sic', 'specify', 'typeset'], 'show': ['bear witness', 'demo', 'demonstrate', 'depict', 'designate', 'establish', 'evidence', 'evince', 'exhibit', 'express', 'indicate', 'picture', 'point', 'present', 'prove', 'read', 'record', 'register', 'render', 'shew', 'show', 'show up', 'testify', 'usher'], 'solve': ['clear', 'figure out', 'lick', 'puzzle out', 'resolve', 'solve', 'work', 'work out'], 'sort': ['assort', 'class', 'classify', 'screen', 'screen out', 'separate', 'sieve', 'sort', 'sort out'], 'sorted': ['assort', 'class', 'classify', 'screen', 'screen out', 'separate', 'sieve', 'sort', 'sort out'], 'sorting': ['assort', 'class', 'classify', 'screen', 'screen out', 'separate', 'sieve', 'sort', 'sort out'], 'stack': ['heap', 'pile', 'stack'], 'steps': ['abuse', 'ill-treat', 'ill-use', 'maltreat', 'mistreat', 'pace', 'step', 'tread'], 'string': ['draw', 'string', 'string along', 'string up', 'thread'], 'structure': ['structure'], 'structures': ['structure'], 'struggling': ['clamber', 'contend', 'fight', 'scramble', 'shin', 'shinny', 'skin', 'sputter', 'struggle'], 'supply': ['add', 'append', 'cater', 'furnish', 'issue', 'ply', 'provide', 'render', 'supply'], 'supposed': ['conjecture', 'guess', 'hypothecate', 'hypothesise', 'hypothesize', 'imagine', 'opine', 'presuppose', 'reckon', 'say', 'speculate', 'suppose', 'theorise', 'theorize', 'think'], 'sways': ['carry', 'persuade', 'rock', 'shake', 'sway', 'swing'], 'table': ['defer', 'hold over', 'postpone', 'prorogue', 'put off', 'put over', 'remit', 'set back', 'shelve', 'table', 'tabularise', 'tabularize', 'tabulate'], 'tables': ['defer', 'hold over', 'postpone', 'prorogue', 'put off', 'put over', 'remit', 'set back', 'shelve', 'table', 'tabularise', 'tabularize', 'tabulate'], 'tell': ['assure', 'differentiate', 'distinguish', 'enjoin', 'evidence', 'narrate', 'order', 'recite', 'recount', 'say', 'secern', 'secernate', 'separate', 'severalise', 'severalize', 'state', 'tell', 'tell apart'], 'tests': ['essay', 'examine', 'prove', 'quiz', 'screen', 'test', 'try', 'try out'], 'troubleshoot': ['trouble-shoot', 'troubleshoot'], 'trying': ['adjudicate', 'assay', 'attempt', 'essay', 'examine', 'hear', 'judge', 'prove', 'render', 'sample', 'seek', 'strain', 'stress', 'taste', 'test', 'try', 'try on', 'try out'], 'understand': ['empathise', 'empathize', 'infer', 'interpret', 'read', 'realise', 'realize', 'see', 'sympathise', 'sympathize', 'translate', 'understand'], 'understanding': ['empathise', 'empathize', 'infer', 'interpret', 'read', 'realise', 'realize', 'see', 'sympathise', 'sympathize', 'translate', 'understand'], 'up': ['up'], 'uploads': ['upload'], 'use': ['apply', 'employ', 'expend', 'habituate', 'practice', 'use', 'utilise', 'utilize'], 'using': ['apply', 'employ', 'expend', 'habituate', 'practice', 'use', 'utilise', 'utilize'], 'validate': ['corroborate', 'formalise', 'formalize', 'validate'], 'want': ['desire', 'need', 'require', 'want'], 'web': ['net', 'web'], 'write': ['compose', 'drop a line', 'indite', 'pen', 'publish', 'save', 'spell', 'write'], 'writing': ['compose', 'drop a line', 'indite', 'pen', 'publish', 'save', 'spell', 'write'], 'wrong': ['wrong']}\n",
      "Original dataset size: 948, Augmented dataset size: 10240\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('large_programming_prompts.json')\n",
    "augmented_data = augment_data(data, augment_factor=10)\n",
    "save_augmented_dataset(augmented_data)\n",
    "print(f\"Original dataset size: {len(data)}, Augmented dataset size: {len(augmented_data)}\")\n",
    "#random.shuffle(augmented_data)\n",
    "train_size = int(0.8 * len(augmented_data))\n",
    "train_data, val_data = augmented_data[:train_size], augmented_data[train_size:]\n",
    "all_texts = [pair[0] for pair in augmented_data] + [pair[1] for pair in augmented_data]\n",
    "vocab, inv_vocab = build_vocab(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59111a57-6ede-4072-9ae8-880fbe534698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abuse',\n",
       " 'accomplish',\n",
       " 'account',\n",
       " 'acknowledge',\n",
       " 'acquire',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actioning',\n",
       " 'actions',\n",
       " 'add',\n",
       " 'address',\n",
       " 'adjudicate',\n",
       " 'adjust',\n",
       " 'afford',\n",
       " 'agree',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'align',\n",
       " 'aligns',\n",
       " 'allow',\n",
       " 'altercate',\n",
       " 'amount',\n",
       " 'annul',\n",
       " 'answer',\n",
       " 'anticipate',\n",
       " 'appear',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applyed',\n",
       " 'approach',\n",
       " 'argufy',\n",
       " 'arise',\n",
       " 'arrange',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'arrest',\n",
       " 'ascertain',\n",
       " 'ask',\n",
       " 'assay',\n",
       " 'assist',\n",
       " 'associate',\n",
       " 'associateing',\n",
       " 'assort',\n",
       " 'assorted',\n",
       " 'assorting',\n",
       " 'assure',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'automate',\n",
       " 'automatise',\n",
       " 'automatize',\n",
       " 'avail',\n",
       " 'await',\n",
       " 'award',\n",
       " 'axe',\n",
       " 'back',\n",
       " 'backs',\n",
       " 'bang',\n",
       " 'base',\n",
       " 'baseing',\n",
       " 'bash',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'behave',\n",
       " 'belong',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'bid',\n",
       " 'birth',\n",
       " 'blame',\n",
       " 'blend',\n",
       " 'blends',\n",
       " 'bonk',\n",
       " 'bop',\n",
       " 'border',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'bucket',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'bump',\n",
       " 'buy',\n",
       " 'calculate',\n",
       " 'call',\n",
       " 'can',\n",
       " 'care',\n",
       " 'carry',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'cater',\n",
       " 'cause',\n",
       " 'cave',\n",
       " 'cede',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channelise',\n",
       " 'channelize',\n",
       " 'charge',\n",
       " 'charges',\n",
       " 'check',\n",
       " 'checker',\n",
       " 'chequer',\n",
       " 'chink',\n",
       " 'chip',\n",
       " 'chips',\n",
       " 'choke',\n",
       " 'cipher',\n",
       " 'clamber',\n",
       " 'clarify',\n",
       " 'class',\n",
       " 'classed',\n",
       " 'classify',\n",
       " 'classifyed',\n",
       " 'classifying',\n",
       " 'classing',\n",
       " 'clear',\n",
       " 'close',\n",
       " 'closet',\n",
       " 'closeted',\n",
       " 'closets',\n",
       " 'closure',\n",
       " 'closures',\n",
       " 'cloture',\n",
       " 'coalesce',\n",
       " 'code',\n",
       " 'codeed',\n",
       " 'cognise',\n",
       " 'cognize',\n",
       " 'coif',\n",
       " 'coiffe',\n",
       " 'coiffure',\n",
       " 'collapse',\n",
       " 'colligate',\n",
       " 'colligateing',\n",
       " 'combine',\n",
       " 'come',\n",
       " 'command',\n",
       " 'commingle',\n",
       " 'commit',\n",
       " 'compare',\n",
       " 'compensate',\n",
       " 'compose',\n",
       " 'comprise',\n",
       " 'compute',\n",
       " 'con',\n",
       " 'condition',\n",
       " 'conduct',\n",
       " 'conflate',\n",
       " 'confront',\n",
       " 'congeal',\n",
       " 'conjecture',\n",
       " 'conjoin',\n",
       " 'conk',\n",
       " 'connect',\n",
       " 'connecting',\n",
       " 'consecrate',\n",
       " 'constitute',\n",
       " 'construct',\n",
       " 'constructed',\n",
       " 'contain',\n",
       " 'containerise',\n",
       " 'containerize',\n",
       " 'contend',\n",
       " 'contribute',\n",
       " 'contrive',\n",
       " 'control',\n",
       " 'convey',\n",
       " 'correct',\n",
       " 'correspond',\n",
       " 'corroborate',\n",
       " 'cost',\n",
       " 'count',\n",
       " 'countermand',\n",
       " 'countersink',\n",
       " 'cover',\n",
       " 'crack',\n",
       " 'create',\n",
       " 'croak',\n",
       " 'crystalise',\n",
       " 'crystalize',\n",
       " 'crystallize',\n",
       " 'curb',\n",
       " 'cypher',\n",
       " 'cyphered',\n",
       " 'deal',\n",
       " 'debug',\n",
       " 'decease',\n",
       " 'decide',\n",
       " 'declare',\n",
       " 'dedicate',\n",
       " 'defer',\n",
       " 'defers',\n",
       " 'define',\n",
       " 'delay',\n",
       " 'delight',\n",
       " 'delineate',\n",
       " 'deliver',\n",
       " 'demand',\n",
       " 'demo',\n",
       " 'demonstrate',\n",
       " 'depart',\n",
       " 'depend',\n",
       " 'depict',\n",
       " 'deport',\n",
       " 'deposit',\n",
       " 'describe',\n",
       " 'design',\n",
       " 'designate',\n",
       " 'desire',\n",
       " 'detail',\n",
       " 'detailed',\n",
       " 'detect',\n",
       " 'determine',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'devote',\n",
       " 'die',\n",
       " 'dies',\n",
       " 'differentiate',\n",
       " 'direct',\n",
       " 'discipline',\n",
       " 'discover',\n",
       " 'dismiss',\n",
       " 'displace',\n",
       " 'dispute',\n",
       " 'distinguish',\n",
       " 'do',\n",
       " 'doting',\n",
       " 'down',\n",
       " 'downs',\n",
       " 'draw',\n",
       " 'dress',\n",
       " 'drive',\n",
       " 'drop',\n",
       " 'e-mail',\n",
       " 'ease',\n",
       " 'eff',\n",
       " 'elucidate',\n",
       " 'email',\n",
       " 'embody',\n",
       " 'empathise',\n",
       " 'empathiseing',\n",
       " 'empathize',\n",
       " 'empathizeing',\n",
       " 'employ',\n",
       " 'encipher',\n",
       " 'encrypt',\n",
       " 'encrypted',\n",
       " 'endure',\n",
       " 'enforce',\n",
       " 'enforceed',\n",
       " 'enjoin',\n",
       " 'enlighten',\n",
       " 'ensure',\n",
       " 'enter',\n",
       " 'enumerate',\n",
       " 'envision',\n",
       " 'equal',\n",
       " 'essay',\n",
       " 'establish',\n",
       " 'estimate',\n",
       " 'evidence',\n",
       " 'evince',\n",
       " 'evolve',\n",
       " 'examine',\n",
       " 'excuse',\n",
       " 'execute',\n",
       " 'executeed',\n",
       " 'exemplify',\n",
       " 'exercise',\n",
       " 'exhibit',\n",
       " 'exist',\n",
       " 'exit',\n",
       " 'expect',\n",
       " 'expend',\n",
       " 'experience',\n",
       " 'expire',\n",
       " 'explain',\n",
       " 'explicate',\n",
       " 'explore',\n",
       " 'express',\n",
       " 'extend',\n",
       " 'externalise',\n",
       " 'externalize',\n",
       " 'extradite',\n",
       " 'fabricate',\n",
       " 'fabricateed',\n",
       " 'face',\n",
       " 'facilitate',\n",
       " 'fail',\n",
       " 'fall',\n",
       " 'fancy',\n",
       " 'fare',\n",
       " 'farm',\n",
       " 'fasten',\n",
       " 'fault',\n",
       " 'feed',\n",
       " 'feel',\n",
       " 'fetch',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'file',\n",
       " 'files',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'fit',\n",
       " 'fix',\n",
       " 'fixate',\n",
       " 'flux',\n",
       " 'follow',\n",
       " 'force',\n",
       " 'forebode',\n",
       " 'forecast',\n",
       " 'foretell',\n",
       " 'fork',\n",
       " 'formalise',\n",
       " 'formalize',\n",
       " 'formulate',\n",
       " 'formulateed',\n",
       " 'founder',\n",
       " 'front',\n",
       " 'fructify',\n",
       " 'fuck',\n",
       " 'fulfil',\n",
       " 'fulfill',\n",
       " 'fulfilled',\n",
       " 'function',\n",
       " 'functions',\n",
       " 'furbish',\n",
       " 'furnish',\n",
       " 'fuse',\n",
       " 'gage',\n",
       " 'game',\n",
       " 'gear',\n",
       " 'generate',\n",
       " 'genuflect',\n",
       " 'germinate',\n",
       " 'get',\n",
       " 'geted',\n",
       " 'gets',\n",
       " 'ghost',\n",
       " 'gibe',\n",
       " 'gift',\n",
       " 'give',\n",
       " 'go',\n",
       " 'going',\n",
       " 'gos',\n",
       " 'grant',\n",
       " 'grate',\n",
       " 'grow',\n",
       " 'guess',\n",
       " 'guide',\n",
       " 'habituate',\n",
       " 'hand',\n",
       " 'handle',\n",
       " 'happen',\n",
       " 'hash',\n",
       " 'have',\n",
       " 'hay',\n",
       " 'head',\n",
       " 'heap',\n",
       " 'hear',\n",
       " 'heel',\n",
       " 'help',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'hump',\n",
       " 'hypothecate',\n",
       " 'hypothesise',\n",
       " 'hypothesize',\n",
       " 'identify',\n",
       " 'ill-treat',\n",
       " 'ill-use',\n",
       " 'illuminate',\n",
       " 'illustrate',\n",
       " 'image',\n",
       " 'imagine',\n",
       " 'immix',\n",
       " 'impart',\n",
       " 'implement',\n",
       " 'implemented',\n",
       " 'incur',\n",
       " 'indicate',\n",
       " 'indite',\n",
       " 'infer',\n",
       " 'infering',\n",
       " 'inscribe',\n",
       " 'inscribeed',\n",
       " 'instance',\n",
       " 'instruct',\n",
       " 'insure',\n",
       " 'interpret',\n",
       " 'interpreting',\n",
       " 'intimate',\n",
       " 'introduce',\n",
       " 'invert',\n",
       " 'involve',\n",
       " 'is',\n",
       " 'issue',\n",
       " 'jazz',\n",
       " 'jell',\n",
       " 'jibe',\n",
       " 'join',\n",
       " 'joining',\n",
       " 'judge',\n",
       " 'junk',\n",
       " 'jut',\n",
       " 'keep',\n",
       " 'key',\n",
       " 'kick',\n",
       " 'know',\n",
       " 'kowtow',\n",
       " 'laid',\n",
       " 'larn',\n",
       " 'last',\n",
       " 'lay',\n",
       " 'lead',\n",
       " 'leads',\n",
       " 'lean',\n",
       " 'learn',\n",
       " 'leave',\n",
       " 'lick',\n",
       " 'lie',\n",
       " 'lift',\n",
       " 'limit',\n",
       " 'line',\n",
       " 'link',\n",
       " 'linked',\n",
       " 'linking',\n",
       " 'list',\n",
       " 'litigate',\n",
       " 'litigateing',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'localise',\n",
       " 'localize',\n",
       " 'locomote',\n",
       " 'lodge',\n",
       " 'lodges',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'love',\n",
       " 'low',\n",
       " 'make',\n",
       " 'makeed',\n",
       " 'maltreat',\n",
       " 'manage',\n",
       " 'maneuver',\n",
       " 'manipulate',\n",
       " 'manoeuver',\n",
       " 'manoeuvre',\n",
       " 'manufacture',\n",
       " 'manufactureed',\n",
       " 'march',\n",
       " 'marching',\n",
       " 'mark',\n",
       " 'master',\n",
       " 'match',\n",
       " 'meld',\n",
       " 'memorise',\n",
       " 'memorize',\n",
       " 'merge',\n",
       " 'mistreat',\n",
       " 'mix',\n",
       " 'moderate',\n",
       " 'modernise',\n",
       " 'modernize',\n",
       " 'modernizeed',\n",
       " 'move',\n",
       " 'name',\n",
       " 'narrate',\n",
       " 'near',\n",
       " 'necessitate',\n",
       " 'need',\n",
       " 'net',\n",
       " 'netmail',\n",
       " 'notice',\n",
       " 'number',\n",
       " 'numerate',\n",
       " 'observe',\n",
       " 'obtain',\n",
       " 'off',\n",
       " 'offer',\n",
       " 'officiate',\n",
       " 'officiates',\n",
       " 'offs',\n",
       " 'open',\n",
       " 'operate',\n",
       " 'operates',\n",
       " 'opine',\n",
       " 'optimise',\n",
       " 'optimize',\n",
       " 'order',\n",
       " 'originate',\n",
       " 'out',\n",
       " 'outdo',\n",
       " 'outed',\n",
       " 'outflank',\n",
       " 'outing',\n",
       " 'outperform',\n",
       " 'outs',\n",
       " 'override',\n",
       " 'overrule',\n",
       " 'overthrow',\n",
       " 'overturn',\n",
       " 'pace',\n",
       " 'palm',\n",
       " 'parse',\n",
       " 'pass',\n",
       " 'pay',\n",
       " 'pen',\n",
       " 'perform',\n",
       " 'performed',\n",
       " 'personify',\n",
       " 'persuade',\n",
       " 'phone',\n",
       " 'pick',\n",
       " 'picture',\n",
       " 'pile',\n",
       " 'pitch',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'plant',\n",
       " 'please',\n",
       " 'plow',\n",
       " 'plug',\n",
       " 'plump',\n",
       " 'plumps',\n",
       " 'ply',\n",
       " 'point',\n",
       " 'pop',\n",
       " 'portray',\n",
       " 'pose',\n",
       " 'position',\n",
       " 'postpone',\n",
       " 'postpones',\n",
       " 'postulate',\n",
       " 'practice',\n",
       " 'practise',\n",
       " 'predict',\n",
       " 'prepare',\n",
       " 'present',\n",
       " 'presuppose',\n",
       " 'proceed',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'produce',\n",
       " 'proffer',\n",
       " 'prognosticate',\n",
       " 'program',\n",
       " 'programme',\n",
       " 'programming',\n",
       " 'progress',\n",
       " 'progressed',\n",
       " 'project',\n",
       " 'promise',\n",
       " 'promises',\n",
       " 'propose',\n",
       " 'prorogue',\n",
       " 'prorogues',\n",
       " 'protrude',\n",
       " 'prove',\n",
       " 'provide',\n",
       " 'publish',\n",
       " 'punt',\n",
       " 'purpose',\n",
       " 'put',\n",
       " 'putting',\n",
       " 'puzzle',\n",
       " 'quarrel',\n",
       " 'query',\n",
       " 'question',\n",
       " 'queue',\n",
       " 'quiz',\n",
       " 'ramp',\n",
       " 'range',\n",
       " 'ranges',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'ready',\n",
       " 'realise',\n",
       " 'realiseing',\n",
       " 'realize',\n",
       " 'realizeing',\n",
       " 'rebuild',\n",
       " 'receive',\n",
       " 'recite',\n",
       " 'reckon',\n",
       " 'recognise',\n",
       " 'recognize',\n",
       " 'recompense',\n",
       " 'reconstruct',\n",
       " 'record',\n",
       " 'recount',\n",
       " 'recover',\n",
       " 'recreate',\n",
       " 'recrudesceed',\n",
       " 'regain',\n",
       " 'register',\n",
       " 'registers',\n",
       " 'reintroduce',\n",
       " 'relate',\n",
       " 'relateing',\n",
       " 'remediate',\n",
       " 'remedy',\n",
       " 'remit',\n",
       " 'remits',\n",
       " 'render',\n",
       " 'renovate',\n",
       " 'repair',\n",
       " 'repeal',\n",
       " 'report',\n",
       " 'represent',\n",
       " 'require',\n",
       " 'rescind',\n",
       " 'research',\n",
       " 'resolve',\n",
       " 'resort',\n",
       " 'rest',\n",
       " 'restore',\n",
       " 'resubmit',\n",
       " 'retard',\n",
       " 'retrace',\n",
       " 'retrieve',\n",
       " 'return',\n",
       " 'reverse',\n",
       " 'revoke',\n",
       " 'rework',\n",
       " 'rifle',\n",
       " 'rig',\n",
       " 'ring',\n",
       " 'rise',\n",
       " 'rock',\n",
       " 'roll',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'runs',\n",
       " 'sack',\n",
       " 'sacrifice',\n",
       " 'salute',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'say',\n",
       " 'scoop',\n",
       " 'scramble',\n",
       " 'scrap',\n",
       " 'scrape',\n",
       " 'scraping',\n",
       " 'scratch',\n",
       " 'screen',\n",
       " 'screened',\n",
       " 'screening',\n",
       " 'screw',\n",
       " 'script',\n",
       " 'search',\n",
       " 'secern',\n",
       " 'secernate',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seek',\n",
       " 'seem',\n",
       " 'send',\n",
       " 'separate',\n",
       " 'separateed',\n",
       " 'separateing',\n",
       " 'sequence',\n",
       " 'serve',\n",
       " 'serveing',\n",
       " 'serves',\n",
       " 'set',\n",
       " 'setting',\n",
       " 'settle',\n",
       " 'severalise',\n",
       " 'severalize',\n",
       " 'sex',\n",
       " 'shake',\n",
       " 'shelve',\n",
       " 'shelves',\n",
       " 'shew',\n",
       " 'shin',\n",
       " 'shinny',\n",
       " 'short',\n",
       " 'show',\n",
       " 'sic',\n",
       " 'sieve',\n",
       " 'sieveed',\n",
       " 'sieveing',\n",
       " 'skin',\n",
       " 'sleep',\n",
       " 'snuff',\n",
       " 'sock',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sorted',\n",
       " 'sorting',\n",
       " 'sound',\n",
       " 'space',\n",
       " 'specify',\n",
       " 'speculate',\n",
       " 'spell',\n",
       " 'spring',\n",
       " 'sputter',\n",
       " 'stack',\n",
       " 'stage',\n",
       " 'stake',\n",
       " 'start',\n",
       " 'state',\n",
       " 'steer',\n",
       " 'step',\n",
       " 'steps',\n",
       " 'sterilize',\n",
       " 'stick',\n",
       " 'stop',\n",
       " 'straighten',\n",
       " 'strain',\n",
       " 'stress',\n",
       " 'string',\n",
       " 'structure',\n",
       " 'structures',\n",
       " 'struggle',\n",
       " 'struggling',\n",
       " 'study',\n",
       " 'submit',\n",
       " 'sue',\n",
       " 'sueing',\n",
       " 'suffice',\n",
       " 'supply',\n",
       " 'suppose',\n",
       " 'supposed',\n",
       " 'surrender',\n",
       " 'survive',\n",
       " 'survives',\n",
       " 'sway',\n",
       " 'sways',\n",
       " 'swear',\n",
       " 'swing',\n",
       " 'sympathise',\n",
       " 'sympathiseing',\n",
       " 'sympathize',\n",
       " 'sympathizeing',\n",
       " 'table',\n",
       " 'tables',\n",
       " 'tabularise',\n",
       " 'tabularises',\n",
       " 'tabularize',\n",
       " 'tabularizes',\n",
       " 'tabulate',\n",
       " 'tabulates',\n",
       " 'take',\n",
       " 'tally',\n",
       " 'taste',\n",
       " 'teach',\n",
       " 'telephone',\n",
       " 'tell',\n",
       " 'tender',\n",
       " 'terminate',\n",
       " 'test',\n",
       " 'testify',\n",
       " 'tests',\n",
       " 'theorise',\n",
       " 'theorize',\n",
       " 'think',\n",
       " 'thread',\n",
       " 'throw',\n",
       " 'tick',\n",
       " 'tie',\n",
       " 'tieing',\n",
       " 'tin',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'touching',\n",
       " 'trace',\n",
       " 'train',\n",
       " 'translate',\n",
       " 'translateing',\n",
       " 'trash',\n",
       " 'travel',\n",
       " 'tread',\n",
       " 'treat',\n",
       " 'treating',\n",
       " 'trouble-shoot',\n",
       " 'troubleshoot',\n",
       " 'trump',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'typeset',\n",
       " 'typesetting',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'unify',\n",
       " 'unite',\n",
       " 'uniteing',\n",
       " 'up',\n",
       " 'uped',\n",
       " 'upes',\n",
       " 'uping',\n",
       " 'upload',\n",
       " 'uploads',\n",
       " 'uprise',\n",
       " 'ups',\n",
       " 'use',\n",
       " 'usher',\n",
       " 'using',\n",
       " 'utilise',\n",
       " 'utilize',\n",
       " 'vacate',\n",
       " 'validate',\n",
       " 'verify',\n",
       " 'visualise',\n",
       " 'visualize',\n",
       " 'volunteer',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'watch',\n",
       " 'web',\n",
       " 'whap',\n",
       " 'whop',\n",
       " 'wield',\n",
       " 'wind',\n",
       " 'witness',\n",
       " 'word',\n",
       " 'work',\n",
       " 'working',\n",
       " 'works',\n",
       " 'write',\n",
       " 'writing',\n",
       " 'wrong',\n",
       " 'yield',\n",
       " 'yoke']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_verbs_from_dataset(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c515163e-2082-472c-9c9f-cd882b43bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PromptDataset(train_data, vocab)\n",
    "val_dataset = PromptDataset(val_data, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d054ae-29f9-4723-b5f9-c71e9939783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Sample Input: show me how to explain the difference between synchronous and asynchronous programming in javascript ?\n",
      "Epoch 1, Sample Output: implement rest api in node.js\n",
      "Epoch 1, Train Loss: 2.9819, Val Loss: 3.9078, TF Ratio: 0.50\n",
      "Epoch 2, Train Loss: 1.9258, Val Loss: 3.1115, TF Ratio: 0.49\n",
      "Epoch 3, Train Loss: 1.1767, Val Loss: 1.3054, TF Ratio: 0.47\n",
      "Epoch 4, Train Loss: 0.7372, Val Loss: 1.0148, TF Ratio: 0.46\n",
      "Epoch 5, Train Loss: 0.6526, Val Loss: 0.9661, TF Ratio: 0.45\n",
      "Epoch 6, Sample Input: show me how to explain the difference between synchronous and asynchronous programming in javascript ?\n",
      "Epoch 6, Sample Output: explain synchronous vs asynchronous programming in javascript\n",
      "Epoch 6, Train Loss: 0.6112, Val Loss: 1.0160, TF Ratio: 0.43\n",
      "Epoch 7, Train Loss: 0.5897, Val Loss: 0.9301, TF Ratio: 0.42\n",
      "Epoch 8, Train Loss: 0.5699, Val Loss: 0.9141, TF Ratio: 0.41\n",
      "Epoch 9, Train Loss: 0.5581, Val Loss: 0.9041, TF Ratio: 0.39\n",
      "Epoch 10, Train Loss: 0.5353, Val Loss: 0.9193, TF Ratio: 0.38\n",
      "Epoch 11, Sample Input: show me how to explain the difference between synchronous and asynchronous programming in javascript ?\n",
      "Epoch 11, Sample Output: explain synchronous vs asynchronous programming in javascript\n",
      "Epoch 11, Train Loss: 0.5200, Val Loss: 0.9094, TF Ratio: 0.37\n",
      "Epoch 12, Train Loss: 0.4952, Val Loss: 0.8972, TF Ratio: 0.35\n",
      "Epoch 13, Train Loss: 0.4783, Val Loss: 0.9099, TF Ratio: 0.34\n",
      "Epoch 14, Train Loss: 0.4609, Val Loss: 0.9360, TF Ratio: 0.33\n",
      "Epoch 15, Train Loss: 0.4319, Val Loss: 0.9290, TF Ratio: 0.31\n",
      "Epoch 16, Sample Input: show me how to explain the difference between synchronous and asynchronous programming in javascript ?\n",
      "Epoch 16, Sample Output: explain synchronous vs asynchronous programming in javascript\n",
      "Epoch 16, Train Loss: 0.4123, Val Loss: 0.9476, TF Ratio: 0.30\n",
      "Epoch 17, Train Loss: 0.4024, Val Loss: 0.9546, TF Ratio: 0.29\n",
      "Epoch 18, Train Loss: 0.3710, Val Loss: 1.0073, TF Ratio: 0.27\n",
      "Epoch 19, Train Loss: 0.3594, Val Loss: 0.9830, TF Ratio: 0.26\n",
      "Epoch 20, Train Loss: 0.3309, Val Loss: 1.0226, TF Ratio: 0.25\n",
      "Epoch 21, Sample Input: show me how to explain the difference between synchronous and asynchronous programming in javascript ?\n",
      "Epoch 21, Sample Output: explain synchronous vs asynchronous programming in javascript\n",
      "Epoch 21, Train Loss: 0.3120, Val Loss: 1.0603, TF Ratio: 0.23\n",
      "Epoch 22, Train Loss: 0.2879, Val Loss: 1.0522, TF Ratio: 0.22\n",
      "Epoch 23, Train Loss: 0.2719, Val Loss: 1.1148, TF Ratio: 0.21\n",
      "Epoch 24, Train Loss: 0.2557, Val Loss: 1.1304, TF Ratio: 0.19\n",
      "Epoch 25, Train Loss: 0.2445, Val Loss: 1.1420, TF Ratio: 0.18\n",
      "Epoch 26, Sample Input: show me how to explain the difference between synchronous and asynchronous programming in javascript ?\n",
      "Epoch 26, Sample Output: explain synchronous vs asynchronous programming in javascript\n",
      "Epoch 26, Train Loss: 0.2184, Val Loss: 1.2068, TF Ratio: 0.17\n",
      "Epoch 27, Train Loss: 0.1989, Val Loss: 1.2434, TF Ratio: 0.15\n",
      "Epoch 28, Train Loss: 0.1887, Val Loss: 1.2715, TF Ratio: 0.14\n",
      "Epoch 29, Train Loss: 0.1952, Val Loss: 1.3074, TF Ratio: 0.13\n",
      "Epoch 30, Train Loss: 0.1659, Val Loss: 1.3319, TF Ratio: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Seq2Seq(vocab_size=len(vocab), embed_size=128, hidden_size=256)\n",
    "\n",
    "# Train model\n",
    "train_model(model, train_loader, val_loader, epochs=30, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "557c1c25-fde9-41ba-88ea-ef30dcbc9522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: show me how to explain the difference between synchronous and asynchronous \n",
      "Enhanced: explain synchronous vs asynchronous programmeming in javascript\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"show me how to explain the difference between synchronous and asynchronous \"\n",
    "enhanced = enhance_prompt(model, test_prompt, vocab, inv_vocab, device=device)\n",
    "print(f\"Original: {test_prompt}\")\n",
    "print(f\"Enhanced: {enhanced}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "976c9f4d-1ccf-491e-8138-b79485cafc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6a769-a1af-47cd-a9b8-00cce90b2b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
